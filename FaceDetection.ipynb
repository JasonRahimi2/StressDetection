{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773590a0-6091-410f-8ab2-6a7ba2607770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "from better_bing_image_downloader import downloader\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b357f4-fe29-4698-8429-d0491afe0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = ['Space', 'Applicances', 'Furniture', 'Vegetables', 'Walls', 'Screens', 'Plants', 'Fruits',\n",
    "           'Boats', 'Nature', 'Buildings', 'Pets', 'Computers', 'Cars', 'Planes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58219ac2-2757-49f0-a55c-945e77e50123",
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in queries:\n",
    "    downloader(query, limit=32, output_dir='/No_Faces_Image_Download', filter='photo', name=query) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba101a33-05b1-431a-9a7e-100baf16916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files(src_dir, dst_dir, num_files):\n",
    "    for root, dirs, files in os.walk(src_dir):\n",
    "        for dir_name in dirs:\n",
    "            dir_path = os.path.join(root, dir_name)\n",
    "            files_in_dir = os.listdir(dir_path)\n",
    "            selected_files = files_in_dir[:num_files]\n",
    "    \n",
    "            for file_name in selected_files:\n",
    "                src_file = os.path.join(dir_path, file_name)\n",
    "                dst_file = os.path.join(dst_dir, file_name)\n",
    "                shutil.copy(src_file, dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b3edc77-acf8-45c5-983e-4ddef797db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = '/No_Faces_Image_Download'\n",
    "dst_dir = '/FaceDetection/Train/No_Faces'\n",
    "num_files = 26\n",
    "copy_files(src_dir, dst_dir, num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8d228e-a162-41c8-8e15-99b505e787bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = '/No_Faces_Image_Download'\n",
    "dst_dir = '/FaceDetection/Test/No_Faces'\n",
    "num_files = 6\n",
    "copy_files(sir_dir, dst_dir, num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c22b2c-94d5-47b3-943a-c86ef9d7d13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = '/Kaggle_Faces/train'\n",
    "dst_dir = 'FaceDetection/Train/Faces'\n",
    "num_files = 26\n",
    "copy_files(sir_dir, dst_dir, num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0994ed-119d-4870-a725-a1e56321f69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = '/Kaggle_Faces/test'\n",
    "dst_dir = 'FaceDetection/Test/Faces'\n",
    "num_files = 6\n",
    "copy_files(sir_dir, dst_dir, num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0724dc9-3dda-4856-84f7-5d2b8573f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/FaceDetection/Train'\n",
    "valid_path = '/FaceDetection/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49063fcb-f5ee-4a67-80da-9fe951797c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input, rescale=1./255, rotation_range=20, zoom_range=(0.8, 1.2), horizontal_flip=True).flow_from_directory(directory=train_path, target_size=(224, 224), classes=['Faces', 'No_Faces'], batch_size=64, shuffle=True)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input, rescale=1./255, rotation_range=20, zoom_range=(0.8, 1.2), horizontal_flip=True).flow_from_directory(directory=valid_path, target_size=(224, 224), classes=['Faces', 'No_Faces'], batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9f27bb-cd61-400e-8194-95ec55f916e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244cdc13-d43d-4e0f-ad3e-7cd46f92c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd463a4-704e-4fa3-93c9-b156de2fc7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotImages(imgs)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93fcc67-628d-46f3-a30b-207b61dc9de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights = 'imagenet', include_top=False, input_shape = (224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd01de5-3914-4cc6-a3b8-4309777e95d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8364e974-c2c5-43af-ad3e-eec894ee2f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    base_model,\n",
    "    Dropout(0.5),\n",
    "    Dense(512),\n",
    "    Dropout(0.5),\n",
    "    Dense(256),\n",
    "    Flatten(),\n",
    "    Dense(units=2, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fa424e-3c95-4d51-89b6-8bde54ff4815",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa3d8a7-1a7b-427b-8d22-5d6911e87323",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='BinaryCrossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555abb9e-d9fb-43fd-998d-2e6866b2ee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=train_batches, validation_data=valid_batches, class_weight={0: 1.0, 1: 1.0}, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb03d67-f070-4b0e-ad77-23c6363dd1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, target_size=(224, 224)):\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize(target_size)\n",
    "    img_array = np.array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = tf.keras.applications.vgg16.preprocess_input(img_array)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af87287-3fc7-4db0-ac2b-0370d2407890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image_class(img_path, model):\n",
    "    preprocessed_img = preprocess_image(img_path)\n",
    "    PlotImages(preprocessed_img)\n",
    "    predictions = model.predict(preprocessed_img)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c37281-d573-4257-a3e8-ba9e40b71329",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '.../image.jpg'\n",
    "predicted_class = predict_image_class(img_path, model)\n",
    "print(f'model is this confident the image shows a face: {predicted_class[0][0]} and this confident the image does not show a face: {predicted_class[0][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02239d4-4cb1-4ccf-83c0-1f6e7b3e4415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('FaceDetection.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
